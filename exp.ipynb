{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from loaddata import defineTestSet,defineResponse,defineFeatures,defineTrainingSets,defineSplits\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tools.model_roc import get_model_roc\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from config import rand_var,ml_dir,ml_model_filename,ensemble_dir\n",
    "\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "whichFeats='chemo'\n",
    "her2=0\n",
    "rcut = 1\n",
    "feats = defineFeatures(whichFeats, her2=her2)\n",
    "\n",
    "with open(ml_dir+ml_model_filename,'rb') as w:\n",
    "    ml_dict=pickle.load(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train = pd.read_csv('inputs/training_df.csv')\n",
    "\n",
    "Xtrain, ytrainCateg, ytrainScore, ytrainID = defineTrainingSets(df_train, feats, her2=her2)\n",
    "\n",
    "splits = defineSplits(Xtrain, ytrainCateg)\n",
    "\n",
    "ytrain_pCR = defineResponse(df_train, 'pCR', her2=her2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "used_model_list = [\n",
    "    ('Logistic Regression',ml_dict[\"Logistic Regression\"]),\n",
    "    ('Random Forest Classifier',ml_dict[\"Random Forest Classifier\"]),\n",
    "    ('Support Vector Classifier',ml_dict['Support Vector Classifier']),\n",
    "    ('Gradient Boosting',ml_dict['Support Vector Classifier']),\n",
    "    ('Gaussean Naive Bayes',ml_dict['Gaussean Naive Bayes']),\n",
    "    ('Adaptive Boosting Classifier',ml_dict['Adaptive Boosting Classifier']),\n",
    "    ('k-Nearest Neighbors',ml_dict['k-Nearest Neighbors']),\n",
    "\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "min_weight =0\n",
    "max_weight = 3\n",
    "\n",
    "weights_of_models = range(min_weight,max_weight,1)\n",
    "\n",
    "possible_combinations = [\n",
    "    [w1,w2,w3,w4,w5,w6,w7]\n",
    "    for w1 in weights_of_models\n",
    "    for w2 in weights_of_models\n",
    "    for w3 in weights_of_models\n",
    "    for w4 in weights_of_models\n",
    "    for w5 in weights_of_models\n",
    "    for w6 in weights_of_models\n",
    "    for w7 in weights_of_models\n",
    "]\n",
    "\n",
    "filtered_combinations = [i for i in possible_combinations if any(i)]\n",
    "\n",
    "\n",
    "param_grid = {\n",
    " 'weights':filtered_combinations   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luejay\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 2186 is smaller than n_iter=20000. Running 2186 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\luejay\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ensemble_model_weighted = VotingClassifier(estimators=used_model_list, voting='soft')\n",
    "\n",
    "ensemble_search = RandomizedSearchCV(ensemble_model_weighted, param_grid, cv=splits,scoring='roc_auc',return_train_score=True, n_jobs=-1, verbose=0,n_iter=1500,random_state=rand_var)\n",
    "\n",
    "ensemble_search.fit(Xtrain,ytrain_pCR)\n",
    "\n",
    "best_ensemble_model = ensemble_search.best_estimator_\n",
    "\n",
    "ensemble_model_weight = ensemble_search.best_params_['weights']\n",
    "\n",
    "print(ensemble_model_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "os.makedirs(ensemble_dir, exist_ok=True)\n",
    "\n",
    "tm = datetime.now()\n",
    "\n",
    "filename = \"ensemble_models_made/Modelnum_{}_random_{}_Feats_{}_Date_{}_{}_{}_{}.p\".format(len(ml_dict),rand_var,whichFeats,tm.year,tm.month,tm.day,tm.strftime(\"%H_%M_%S\"))\n",
    "\n",
    "\n",
    "with open(filename,'wb') as w:\n",
    "    pickle.dump(best_ensemble_model,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare test data\n",
    "\n",
    "df_test_pCR_pos = pd.read_csv('inputs//testing_her2pos_df.csv')\n",
    "df_test_pCR_neg = pd.read_csv('inputs//testing_her2neg_df.csv')\n",
    "\n",
    "x_test_pCR_pos = defineTestSet(df_test_pCR_pos,feats,her2=her2)\n",
    "y_test_pCR_pos = defineResponse(df_test_pCR_pos, 'pCR', her2=her2)\n",
    "\n",
    "x_test_pCR_neg = defineTestSet(df_test_pCR_neg,feats,her2=her2)\n",
    "y_test_pCR_neg = defineResponse(df_test_pCR_neg, 'pCR', her2=her2)\n",
    "\n",
    "y_test_comb = pd.concat([y_test_pCR_pos,y_test_pCR_neg])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_roc_results = get_model_roc(x_test_pCR_pos,x_test_pCR_neg,y_test_comb,ml_dict)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i,(tr,ts) in enumerate(splits):\n",
    "    \n",
    "    xtrain_tr = Xtrain.iloc[tr,:]\n",
    "    ytrain_tr = ytrain_pCR.iloc[tr]\n",
    "    \n",
    "    \n",
    "    ml_dict[\"Logistic Regression\"].fit(xtrain_tr,ytrain_tr) \n",
    "    ml_dict[\"Random Forest Classifier\"].fit(xtrain_tr,ytrain_tr) \n",
    "    ensemble_model.fit(xtrain_tr,ytrain_tr) \n",
    "    \n",
    "    y_pred_logres = ml_dict[\"Logistic Regression\"].predict(Xtrain.iloc[ts,:])\n",
    "    y_pred_gb = ml_dict[\"Random Forest Classifier\"].predict(Xtrain.iloc[ts,:])\n",
    "    #y_pred_ensemble = ensemble_model.predict(Xtrain.iloc[ts,:])\n",
    " \n",
    "    #fp_rate, tp_rate, thresholds = roc_curve(ytrain_pCR.iloc[ts], y_pred)\n",
    "    \n",
    "    #roc_auc = auc(fp_rate, tp_rate)\n",
    "    #print(roc_auc)\n",
    "    \n",
    "    break\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
